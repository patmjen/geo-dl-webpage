<!DOCTYPE html>
<html lang="en-us" class="wf-firasans-n4-active wf-active">
	<head>
    <link href="http://gmpg.org/xfn/11" rel="profile">
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <!-- Enable responsiveness on mobile devices -->
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">
    
    
    <meta name="generator" content="Hugo 0.83.1" />
    
    <title>Paper Pool &middot; geo-DL</title>
    <meta content="Paper Pool - geo-DL" property="og:title">
    <meta content=" - " property="og:description">
    <!-- CSS -->
    <link href="https://fonts.googleapis.com/css?family=Fira+Sans:300,300i,400,400i|Roboto+Mono:300,300i,400,400i" rel="stylesheet">
    <link rel="stylesheet" href="http://geo-dl.compute.dtu.dk/css/print.css" media="print">
    <link rel="stylesheet" href="http://geo-dl.compute.dtu.dk/css/poole.css">
    <link rel="stylesheet" href="http://geo-dl.compute.dtu.dk/css/hyde.css">
    <!-- Font-Awesome -->
    <script defer src="https://use.fontawesome.com/releases/v5.0.9/js/all.js" integrity="sha384-8iPTk2s/jMVj81dnzb/iFR2sdA7u06vHJyyLlAd4snFpCl/SnyUjRrbdJsw1pGIl" crossorigin="anonymous"></script>
    
    <!-- Customised CSS -->
    <link rel="stylesheet" href="http://geo-dl.compute.dtu.dk/css/custom.css">
    <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
    <script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
    <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    <![endif]-->
    <!-- Icons -->
    <link rel="apple-touch-icon-precomposed" sizes="144x144" href="/apple-touch-icon-144-precomposed.png">
    <link rel="shortcut icon" href="/favicon.png">
    

	</head>
    <body>
        <div class="sidebar">
	<div class="container text-center sidebar-sticky">
		<div class="sidebar-about text-center">
			<a href="http://geo-dl.compute.dtu.dk/"><h1 class="brand">geo-DL</h1></a>
			
			<p class="lead">
				 Journal club for geometric deep learning 
			</p>
		</div>
		
<div>
	<ul class="sidebar-nav">
		
		
				<li>
					<a href="/posts/"> <span>Posts</span></a>
				</li>
				<li>
					<a href="/about/"> <span>About</span></a>
				</li>
				<li>
					<a href="/papers/"> <span>Paper Pool</span></a>
				</li>
		</li>
	</ul>
</div>

        <p>
		<section class="row text-center">
	
	
	
	
	
	
	
	
	
	
</section>

        </p>
		<p class="copyright">&copy; 2021 .
        <a href="https://creativecommons.org/licenses/by/4.0">Some Rights Reserved</a>.<br/>Built with <a href="https://gohugo.io/">Hugo</a> &amp; <a href="https://github.com/htr3n/hyde-hyde">hyde-hyde</a>.
        </p>
	</div>
	<div>
	</div>
</div>

        <div class="content container">
            <div class="post">
  <h1>Paper Pool</h1>
  
  <div class="col-sm-12 col-md-12">
    <span class="text-left post-date meta">
            
       
        <i class="fas fa-calendar-alt"></i> May 14, 2021
      
      
      
      
      <br/>
      <i class="fas fa-clock"></i> 2 min read 
      </span>  
  </div>    
  
  <h1 id="selection-of-upcoming-papers">Selection of upcoming papers</h1>
<ul>
<li>18-05-2021 by Patrick: <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9003285">Cao et al., A Comprehensive Survey on Geometric Deep Learning, 2020, IEEE Access</a></li>
</ul>
<h1 id="paper-pool">Paper pool</h1>
<p>Old list from the previous version of the journal club. To be updated.</p>
<ul>
<li><a href="http://papers.nips.cc/paper/7095-pointnet-deep-hierarchical-feature-learning-on-point-sets-in-a-metric-space.pdf">PointNet++: Deep Hierarchical Feature Learning on Point Sets in a Metric Space</a></li>
<li><a href="https://arxiv.org/pdf/1711.08488.pdf">Frustum PointNets for 3D Object Detection from RGB-D Data</a></li>
<li><a href="http://3dgan.csail.mit.edu/">Learning a Probabilistic Latent Space of Object Shapes via 3D Generative-Adversarial Modeling, NIPS 2016</a></li>
<li><a href="http://papers.nips.cc/paper/6416-fpnn-field-probing-neural-networks-for-3d-data.pdf">FPNN: Field Probing Neural Networks for 3D Data</a></li>
<li><a href="http://openaccess.thecvf.com/content_cvpr_2017/papers/Dai_Shape_Completion_Using_CVPR_2017_paper.pdf">Shape Completion using 3D-Encoder-Predictor CNNs and Shape Synthesis</a></li>
<li><a href="https://ieeexplore.ieee.org/abstract/document/7526450/">DeepShape: Deep-Learned Shape Descriptor for 3D Shape Retrieval</a></li>
<li><a href="http://papers.nips.cc/paper/6045-learning-shape-correspondence-with-anisotropic-convolutional-neural-networks.pdf">Learning shape correspondence with anisotropic convolutional neural networks</a></li>
<li><a href="https://arxiv.org/pdf/1712.10215.pdf">ScanComplete: Large-Scale Scene Completion and Semantic Segmentation for 3D Scans</a></li>
<li><a href="https://arxiv.org/pdf/1804.03550.pdf">Two Stream 3D Semantic Scene Completion</a></li>
<li><a href="http://www.geometricdeeplearning.com/">Papers from geometric deeplearning.com</a>, papers from this list are added to the covered list if scheduled</li>
<li><a href="https://deepmind.com/blog/neural-scene-representation-and-rendering/">Neural Scene Representation and Rendering</a></li>
<li><a href="https://arxiv.org/abs/1803.07289">Flex-Convolution (Deep Learning Beyond Grid-Worlds)</a></li>
<li><a href="https://arxiv.org/abs/1806.01759">Monte Carlo Convolution for Learning on Non-Uniformly Sampled Point Clouds</a></li>
</ul>
<h2 id="relevant-papers-from-cvpr-2018">Relevant papers from CVPR 2018</h2>
<ul>
<li><a href="http://openaccess.thecvf.com/content_cvpr_2018/papers/Bulat_Super-FAN_Integrated_Facial_CVPR_2018_paper.pdf">Super-FAN: Integrated Facial Landmark Localization and Super-Resolution of Real-World Low Resolution Faces in Arbitrary Poses With GANs</a></li>
<li><a href="http://openaccess.thecvf.com/content_cvpr_2018/CameraReady/0142.pdf">Multi-View Harmonized Bilinear Network for 3D Object Recognition</a></li>
<li><a href="http://openaccess.thecvf.com/content_cvpr_2018/CameraReady/1025.pdf">PPFNet: Global Context Aware Local Features for Robust 3D Point Matching</a></li>
<li><a href="http://openaccess.thecvf.com/content_cvpr_2018/CameraReady/1129.pdf">FoldingNet: Point Cloud Auto-Encoder via Deep Grid Deformation</a></li>
<li><a href="http://openaccess.thecvf.com/content_cvpr_2018/papers/Feng_GVCNN_Group-View_Convolutional_CVPR_2018_paper.pdf">GVCNN: Group-View Convolutional Neural Networks for 3D Shape Recognition</a></li>
<li><a href="http://openaccess.thecvf.com/content_cvpr_2018/CameraReady/3736.pdf">Learning to Estimate 3D Human Pose and Shape From a Single Color Image</a></li>
<li><a href="http://openaccess.thecvf.com/content_cvpr_2018/CameraReady/3827.pdf">SplineCNN: Fast Geometric Deep Learning With Continuous B-Spline Kernels</a></li>
<li><a href="http://openaccess.thecvf.com/content_cvpr_2018/papers/Kossaifi_GAGAN_Geometry-Aware_Generative_CVPR_2018_paper.pdf">GAGAN: Geometry-Aware Generative Adversarial Networks</a></li>
<li><a href="http://openaccess.thecvf.com/content_cvpr_2018/CameraReady/0095.pdf">Deformable Shape Completion With Graph Convolutional Autoencoders</a></li>
<li><a href="http://openaccess.thecvf.com/content_cvpr_2018/papers/Gilani_Learning_From_Millions_CVPR_2018_paper.pdf">Learning From Millions of 3D Scans for Large-Scale 3D Face Recognition</a></li>
<li><a href="http://openaccess.thecvf.com/content_cvpr_2018/CameraReady/0326.pdf">SPLATNet: Sparse Lattice Networks for Point Cloud Processing</a></li>
<li>[Surface Networks](no link available)</li>
<li><a href="http://openaccess.thecvf.com/content_cvpr_2018/CameraReady/0967.pdf">SGPN: Similarity Group Proposal Network for 3D Point Cloud Instance Segmentation</a></li>
<li><a href="http://openaccess.thecvf.com/content_cvpr_2018/CameraReady/2589.pdf">FeaStNet: Feature-Steered Graph Convolutions for 3D Shape Analysis</a></li>
<li><a href="http://openaccess.thecvf.com/content_cvpr_2018/CameraReady/2058.pdf">Recurrent Slice Networks for 3D Segmentation of Point Clouds</a></li>
<li><a href="http://openaccess.thecvf.com/content_cvpr_2018/CameraReady/1248.pdf">PU-Net: Point Cloud Upsampling Network</a></li>
</ul>
<h1 id="articles-covered">Articles covered:</h1>
<ul>
<li><a href="http://openaccess.thecvf.com/content_cvpr_2017/papers/Yi_SyncSpecCNN_Synchronized_Spectral_CVPR_2017_paper.pdf">SyncSpecCNN: Synchronized Spectral CNN for 3D Shape Segmentation</a> (Shihav)</li>
<li><a href="http://openaccess.thecvf.com/content_cvpr_2017/papers/Qi_PointNet_Deep_Learning_CVPR_2017_paper.pdf">PointNet: Deep Learning on Point Sets for 3D Classification and Segmentation</a> (Vladimir)</li>
<li><a href="https://ibug.doc.ic.ac.uk/media/uploads/documents/fg2018_3dalignment.pdf">Cascade Multi-view Hourglass Model for Robust 3D Face Alignment</a> (Kristine)</li>
<li><a href="https://www.cv-foundation.org/openaccess/content_iccv_2015/papers/Su_Multi-View_Convolutional_Neural_ICCV_2015_paper.pdf">Multi-view Convolutional Neural Networks for 3D Shape Recognition</a> (Rasmus)</li>
<li><a href="http://openaccess.thecvf.com/content_cvpr_2016/papers/Qi_Volumetric_and_Multi-View_CVPR_2016_paper.pdf">Volumetric and Multi-View CNNs for Object Classification on 3D Data</a> (Rasmus)</li>
<li><a href="http://papers.nips.cc/paper/5423-generative-adversarial-nets.pdf">Generative Adversarial Nets</a> (Gudmundur)</li>
<li><a href="http://openaccess.thecvf.com/content_ICCV_2017/papers/Zhu_Unpaired_Image-To-Image_Translation_ICCV_2017_paper.pdf">Unpaired image-to-image translation using cycle-consistent adversarial networks</a> (Gudmundur)</li>
</ul>

</div>
            <div class="footer">
                


            </div>
        </div>
        
        
<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
	ga('create', 'UA-126539062-1', 'auto');
	
	ga('send', 'pageview');
}
</script>
<script async src='https://www.google-analytics.com/analytics.js'></script>
        
    </body>
</html>
